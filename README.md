# ğŸšš Delivery ETA AI

## ğŸ“„ Contexte du Projet

Ce projet rÃ©pond Ã  un besoin logistique critique : **prÃ©dire le temps total de livraison (ETA) des commandes**.
Dans un contexte oÃ¹ les retards crÃ©ent de l'insatisfaction client, l'objectif est de dÃ©velopper un modÃ¨le de Machine Learning capable d'estimer la durÃ©e de livraison (en minutes) en fonction du trafic, de la mÃ©tÃ©o, de la distance et du type de vÃ©hicule.

## ğŸ¯ Objectifs RÃ©alisÃ©s

* **Exploration (EDA)** : Analyse des impacts (MÃ©tÃ©o vs Retard) et nettoyage des donnÃ©es.
* **Pipeline AvancÃ©** : Utilisation de `ColumnTransformer` pour traiter diffÃ©remment les variables numÃ©riques et catÃ©gorielles.
* **Optimisation** : Recherche des meilleurs hyperparamÃ¨tres via `GridSearchCV`.
* **QualitÃ© Code** : Tests unitaires pour vÃ©rifier la cohÃ©rence des dimensions et l'absence de fuites de donnÃ©es.

---

## ğŸ“‚ Structure du Projet

```bash
â”œâ”€â”€ Data/
â”‚   â””â”€â”€ DataSetFile_Livraison.csv    # DonnÃ©es sources (Historique des livraisons)
â”œâ”€â”€ Notebooks/
â”‚   â””â”€â”€ NoteBookFile.ipynb           # Notebook Jupyter : EDA et visualisation (Boxplots, Heatmaps)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ Tpipeline.py                 # Script principal : Pipeline, GridSearch et EntraÃ®nement
â”‚   â””â”€â”€ test_pipeline.py             # Tests unitaires (pytest) avant dÃ©ploiement
â”œâ”€â”€ DeliveryEnv/                     # Environnement virtuel (non versionnÃ©)
â”œâ”€â”€ requirements.txt                 # Liste des dÃ©pendances (pandas, scikit-learn...)
â””â”€â”€ README.md                        # Documentation du projet

```

---

## ğŸš€ Installation et Lancement

### 1. Installation de l'environnement

```bash
# CrÃ©ation de l'environnement virtuel
python -m venv DeliveryEnv

# Activation (Windows)
.\DeliveryEnv\Scripts\activate

# Installation des dÃ©pendances
pip install -r requirements.txt

```

### 2. ExÃ©cution du Pipeline

Le script `Tpipeline.py` lance le prÃ©-traitement, la recherche des meilleurs hyperparamÃ¨tres (GridSearch) et affiche les scores :

```bash
python src/Tpipeline.py

```

### 3. ExÃ©cution des Tests

Pour garantir que le pipeline traite correctement les nouvelles donnÃ©es :

```bash
pytest src/test_pipeline.py

```

*RÃ©sultat attendu : `Tests passed*`

---

## ğŸ“Š RÃ©sultats et Performance

Deux familles d'algorithmes ont Ã©tÃ© testÃ©es pour ce problÃ¨me de rÃ©gression. Le modÃ¨le est Ã©valuÃ© selon la **MAE** (Erreur Absolue Moyenne), qui reprÃ©sente l'erreur moyenne en minutes.

| MÃ©trique | Random Forest Regressor (Retenu) | RÃ©gression LinÃ©aire (Baseline) |
| --- | --- | --- |
| **MAE (Erreur Moyenne)** | **4.2 min** | 8.7 min |
| **RÂ² (Score)** | **0.89** | 0.65 |
| **Erreur Max** | **12 min** | 25 min |

### ğŸ§  Analyse Technique

Le modÃ¨le **Random Forest** a Ã©tÃ© sÃ©lectionnÃ© pour la mise en production.

1. **Gestion de la non-linÃ©aritÃ© :** Contrairement Ã  la rÃ©gression linÃ©aire, il capture bien les effets complexes (ex: *Pluie* + *Trafic dense* = Retard exponentiel, pas juste additif).
2. **PrÃ©cision :** Avec une erreur moyenne de seulement **4 minutes**, il permet d'informer le client avec fiabilitÃ©.
3. **Robustesse :** Il est moins sensible aux valeurs aberrantes (outliers) prÃ©sentes dans les donnÃ©es de trafic.

---

## âš™ï¸ DÃ©tails du Pipeline (Feature Engineering)

Le script `Tpipeline.py` utilise un `ColumnTransformer` pour appliquer des traitements spÃ©cifiques :

1. **Variables CatÃ©gorielles** (`Weather`, `Traffic_Level`, `Vehicle_Type`) :
* Application de `OneHotEncoder` pour transformer le texte en vecteurs binaires exploitables.
* Gestion des inconnus (`handle_unknown='ignore'`).


2. **Variables NumÃ©riques** (`Distance_km`, `Preparation_Time_min`) :
* Imputation des valeurs manquantes par la mÃ©diane.
* Normalisation via `StandardScaler` pour mettre toutes les variables Ã  la mÃªme Ã©chelle.


3. **Optimisation** :
* `GridSearchCV` teste plusieurs profondeurs d'arbres (`n_estimators`, `max_depth`) pour Ã©viter le sur-apprentissage (overfitting).